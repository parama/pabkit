{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process-Aware Benchmarking (PAB) Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the PAB toolkit to track and analyze a model's learning trajectory during training. We'll use a simple CNN trained on CIFAR-10 as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add the parent directory to the path to import PAB\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from pab import ProcessAwareBenchmark\n",
    "from pab.visualization import (\n",
    "    plot_learning_trajectory,\n",
    "    plot_class_progression,\n",
    "    plot_robustness_curve,\n",
    "    plot_pab_summary\n",
    ")\n",
    "from pab.utils import compute_class_accuracies, evaluate_adversarial_robustness\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create directory for results\n",
    "os.makedirs('./notebook_results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "We'll use the CIFAR-10 dataset for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "# Class names for CIFAR-10\n",
    "class_names = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "\n",
    "We'll use a simple CNN for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Process-Aware Benchmarking\n",
    "\n",
    "Now, let's set up PAB to track the learning trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize PAB\n",
    "pab = ProcessAwareBenchmark(\n",
    "    checkpoint_dir='./notebook_results/checkpoints',\n",
    "    save_frequency=2,  # Save checkpoints every 2 epochs\n",
    "    track_representations=True\n",
    ")\n",
    "\n",
    "print(f\"PAB initialized with checkpoint directory at {pab.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop with PAB Tracking\n",
    "\n",
    "Let's train our model while tracking the learning trajectory with PAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training function\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
    "    for inputs, targets in progress_bar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': train_loss / (progress_bar.n + 1),\n",
    "            'acc': 100. * correct / total\n",
    "        })\n",
    "    \n",
    "    return train_loss / len(train_loader), correct / total\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return test_loss / len(test_loader), correct / total\n",
    "\n",
    "# Number of epochs to train\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train for one epoch\n",
    "    train_loss, train_acc = train(epoch)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = evaluate()\n",
    "    \n",
    "    # Compute per-class accuracies\n",
    "    class_accuracies = compute_class_accuracies(\n",
    "        model, test_loader, num_classes=10, device=device\n",
    "    )\n",
    "    \n",
    "    # Evaluate adversarial robustness (every 2 epochs to save time)\n",
    "    adversarial_acc = None\n",
    "    if epoch % 2 == 0:\n",
    "        print(\"Evaluating adversarial robustness...\")\n",
    "        adv_metrics = evaluate_adversarial_robustness(\n",
    "            model, test_loader, device=device, epsilon=0.03\n",
    "        )\n",
    "        adversarial_acc = adv_metrics['adversarial_accuracy']\n",
    "        print(f\"Adversarial accuracy: {adversarial_acc:.4f}\")\n",
    "    \n",
    "    # Track metrics with PAB\n",
    "    pab.track_epoch(\n",
    "        model=model,\n",
    "        epoch=epoch,\n",
    "        train_loss=train_loss,\n",
    "        val_loss=test_loss,\n",
    "        train_acc=train_acc,\n",
    "        val_acc=test_acc,\n",
    "        class_accuracies=class_accuracies,\n",
    "        adversarial_acc=adversarial_acc\n",
    "    )\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
    "          f\"Test Loss={test_loss:.4f}, Test Acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Learning Trajectory with PAB\n",
    "\n",
    "Now that we've trained our model and tracked the learning trajectory with PAB, let's analyze the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate the learning trajectory\n",
    "eval_results = pab.evaluate_trajectory()\n",
    "\n",
    "# Print summary\n",
    "summary = pab.summarize()\n",
    "print(\"PAB Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learning Trajectory\n",
    "\n",
    "Let's create some visualizations to better understand the learning trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot learning trajectory\n",
    "plt.figure(figsize=(12, 5))\n",
    "plot_learning_trajectory(\n",
    "    train_losses=pab.metrics['train_loss'],\n",
    "    val_losses=pab.metrics['val_loss'],\n",
    "    train_accs=pab.metrics['train_acc'],\n",
    "    val_accs=pab.metrics['val_acc'],\n",
    "    title=\"Learning Trajectory\",\n",
    "    save_path=\"./notebook_results/learning_trajectory.png\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot class progression\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_class_progression(\n",
    "    class_accuracies=pab.metrics['class_accuracy'],\n",
    "    class_names=class_names,\n",
    "    save_path=\"./notebook_results/class_progression.png\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot adversarial robustness curve\n",
    "if 'adversarial_robustness' in pab.metrics and pab.metrics['adversarial_robustness']:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plot_robustness_curve(\n",
    "        clean_accuracies=pab.metrics['val_acc'],\n",
    "        adversarial_accuracies=pab.metrics['adversarial_robustness'],\n",
    "        save_path=\"./notebook_results/robustness_curve.png\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot PAB summary\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_pab_summary(\n",
    "    metrics=pab.metrics,\n",
    "    save_path=\"./notebook_results/pab_summary.png\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Early vs. Late Learning Classes\n",
    "\n",
    "Let's look at which classes were learned early and which were learned late:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if 'class_patterns' in eval_results:\n",
    "    class_patterns = eval_results['class_patterns']\n",
    "    \n",
    "    print(\"Early learning classes:\")\n",
    "    for class_id in class_patterns.get('early_classes', []):\n",
    "        print(f\"  - Class {class_id} ({class_names[class_id]})\")\n",
    "    \n",
    "    print(\"\\nLate learning classes:\")\n",
    "    for class_id in class_patterns.get('late_classes', []):\n",
    "        print(f\"  - Class {class_id} ({class_names[class_id]})\")\n",
    "else:\n",
    "    print(\"Class patterns not available in evaluation results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Generalization\n",
    "\n",
    "Let's look at the generalization behavior of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if 'generalization' in eval_results:\n",
    "    gen = eval_results['generalization']\n",
    "    \n",
    "    print(\"Generalization Analysis:\")\n",
    "    print(f\"  - Final generalization gap: {gen.get('final_gap', 'Unknown')}\")\n",
    "    print(f\"  - Gap trend: {gen.get('gap_trend', 'Unknown')}\")\n",
    "    print(f\"  - Optimal early stopping epoch: {gen.get('early_stopping_epoch', 'Unknown')}\")\n",
    "else:\n",
    "    print(\"Generalization metrics not available in evaluation results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Robustness\n",
    "\n",
    "Let's look at the adversarial robustness of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if 'robustness' in eval_results:\n",
    "    rob = eval_results['robustness']\n",
    "    \n",
    "    print(\"Adversarial Robustness Analysis:\")\n",
    "    print(f\"  - Peak robustness: {rob.get('peak_value', 0):.4f} at epoch {rob.get('peak_epoch', 0)}\")\n",
    "    print(f\"  - Final robustness: {rob.get('final_value', 0):.4f}\")\n",
    "    print(f\"  - Robustness degradation: {rob.get('degradation', 0)*100:.2f}%\")\n",
    "else:\n",
    "    print(\"Robustness metrics not available in evaluation results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAB Recommendations\n",
    "\n",
    "Based on the PAB analysis, let's see what recommendations we can make for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"PAB Recommendations:\")\n",
    "\n",
    "if 'generalization' in eval_results and eval_results['generalization'].get('gap_trend') == 'increasing':\n",
    "    print(\"  • Model shows signs of overfitting, consider early stopping or regularization.\")\n",
    "\n",
    "if 'robustness' in eval_results and eval_results['robustness'].get('degradation', 0) > 0.1:\n",
    "    print(\"  • Adversarial robustness peaks before final epoch, suggesting robustness-accuracy tradeoff.\")\n",
    "\n",
    "if 'overall_stability' in eval_results and eval_results['overall_stability'].get('std', 0) > 0.1:\n",
    "    print(\"  • Training exhibits instability, consider more stable optimization strategy.\")\n",
    "\n",
    "if 'class_patterns' in eval_results:\n",
    "    num_late = len(eval_results['class_patterns'].get('late_classes', []))\n",
    "    if num_late > 2:\n",
    "        print(f\"  • {num_late} classes are learned late, consider class-balanced training or focal loss.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the Process-Aware Benchmarking (PAB) toolkit to track, analyze, and visualize a model's learning trajectory during training. PAB provides insights beyond traditional static benchmarking, helping you understand how your model learns, when it generalizes, and how its robustness evolves.\n",
    "\n",
    "Key takeaways:\n",
    "- PAB helps identify which classes are learned early and which are learned late\n",
    "- It tracks generalization efficiency throughout training\n",
    "- It monitors adversarial robustness over time\n",
    "- It provides actionable recommendations for improving model performance\n",
    "\n",
    "By incorporating PAB into your ML workflow, you can gain deeper insights into your models and make more informed decisions about training, architecture, and hyperparameter selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
